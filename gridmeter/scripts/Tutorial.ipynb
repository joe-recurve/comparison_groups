{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting starting with the GRIDmeterâ„¢ library\n",
    "\n",
    "This jupyter notebook is an interactive tutorial. It walks through loading data, running the stratified sampling model, and plotting results. You'll run all the code yourself. Cells can be executed with `<shift><enter>`. If you feel so inspired, make edits to the code in these cells and dig deeper.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background -- why this library\n",
    "\n",
    "The `gridmeter` library originated from a project lead by Recurve Analytics, Inc. and funded by the US Dept. of Energy designed to identify practical methods for analyzing energy efficiency which are robust to external shocks (e.g. COVID-19).  From June through September 2020, Recurve hosted a series of meetings with industry stakeholders to discuss methods for constructing comparison groups, with the goal of presenting a recommended standard method to the GRID working group, a subsidiary of the Linux Foundation for Energy.  During this time, Recurve developed Python software to implement stratified sampling and demonstrate its effectiveness in practice.  The `gridmeter` library is the open-source Apache-licensed output of this process and is available to be used by anyone. \n",
    "\n",
    "This notebook will take you through several things that this library can do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on tutorial scope and related libraries\n",
    "\n",
    "This tutorial assumes the reader has properly installed python and has a basic working knowledge of python syntax and usage. \n",
    "\n",
    "The `gridmeter` library uses `pandas` data frames as its principle way of representing data, therefore all inputs and outputs are data frames; see [this tutorial](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html) for information on how to use `pandas`.  The `plotnine` library is used to make visualizations which can be embedded in a Jupyter notebook or saved as .pngs; see [this website](https://plotnine.readthedocs.io/en/stable/) for information on `plotnine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "for package in ['gridmeter', 'pandas', 'plotnine']:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotnine as pn\n",
    "import gridmeter as gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing documentation\n",
    "\n",
    "You can view code documentation by appending a question mark to a function and then executing that code, as in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.Stratified_Sampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem definition\n",
    "\n",
    "Typically one begins with two populations of meters: a **treatment group**, and a **comparison pool**.  The treatment group consists of those meters for which savings needs to be tracked, e.g. if they represent customers participating in an energy efficiency program.  The comparison pool consists of all of the available meters that are not part of the treatment group.  The goal is to select a **comparison group** which is a subset of the comparison pool, such that the control group is **similar** to the treatment group.  The comparison group will then provide a realistic counterfactual compared to the treatment group and can be used to accurately estimate the impact of a program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up tutorial data\n",
    "\n",
    "Ordinarily you would start with your own time-series meter data, but for our purposes we'll generate some very basic dummy data.  `gridmeter` provides some functions which generate populations of dummy meters with randomly varying base and peak usage levels.  We'll use the following code to generate a population of 1000 treatment meters and 10000 comparison pool meters, and specify some consumption values for the treatment group that differ from the default, so that the groups are differently distributed.  The treatment group is specified by filtering the comparison pool along one of the available features (currently `winter_usage`, `summer_uage`, and `annual_usage`).  For this example, we'll assume our treatment group targets customers with usage above the 50th percentile in both summer and winter.\n",
    "\n",
    "Once the population has been generated, we can create feature data and longitudinal data.  These functions take a few minutes to run upon first execution, but the results are cached to disk so subsequent runs will be fast.\n",
    "\n",
    "Note: the structure of the dataframes is extremely important going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadshape and feature data\n",
    "\n",
    "n_treatment = 1000\n",
    "n_pool = 10000\n",
    "\n",
    "filter = lambda df: df[(df.summer_usage > df.summer_usage.quantile(0.5)) & (df.winter_usage > df.winter_usage.quantile(0.5))]\n",
    "population = gm.DummyTreatmentPoolPopulation(n_treatment=n_treatment, n_pool=n_pool, \n",
    "                                              treatment_filter_function=filter)\n",
    "\n",
    "df_features= population.features()\n",
    "df_features_pool = df_features[df_features['set']=='pool']\n",
    "df_features_treatment = df_features[df_features['set']=='treatment']\n",
    "df_loadshape = population.features_monthly()\n",
    "\n",
    "df_features_pool = df_features_pool.rename(columns={'meter_id':'id'}).drop(columns=['set'])\n",
    "df_ls_pool = df_loadshape.loc[df_features_pool[\"id\"]]\n",
    "df_ls_pool = df_ls_pool.stack().reset_index().rename(columns={'meter_id':'id', 'month':'time', 0:'loadshape'})\n",
    "\n",
    "df_features_treatment = df_features_treatment.rename(columns={'meter_id':'id'}).drop(columns=['set'])\n",
    "df_ls_treatment = df_loadshape.loc[df_features_treatment[\"id\"]]\n",
    "df_ls_treatment = df_ls_treatment.stack().reset_index().rename(columns={'meter_id':'id', 'month':'time', 0:'loadshape'})\n",
    "\n",
    "# Fake time series data\n",
    "# Create a testing dataframe having an id, datetime of 1 month intervals, observed and modeled values \n",
    "num_intervals = 12  # 1 per month\n",
    "\n",
    "# Create a DataFrame with 'id', 'datetime', 'observed', and 'modeled' columns\n",
    "df_ts_treatment = pd.DataFrame({\n",
    "    'id': np.repeat(df_features_treatment[\"id\"].values, num_intervals),  # only 3 ids for easier comparison\n",
    "    'datetime': pd.date_range(start='2023-01-01', periods=num_intervals, freq='M').tolist() * n_treatment, \n",
    "    'observed': np.random.rand(num_intervals * n_treatment),  # randomized\n",
    "    'modeled': np.random.rand(num_intervals * n_treatment)  # randomized\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadshape dataframe format, columns: [id, time, loadshape]\n",
    "# time depends on whatever you have aggregated to\n",
    "\n",
    "print(\"Loadshape dataframe format:\")\n",
    "df_ls_treatment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series dataframe format, columns: [id, datetime, Optional[observed], Optional[modeled], Optional[error]]\n",
    "# observed, modeled, and error are optional, but at least one must be present\n",
    "# if you are using observed and modeled to calculate error, then you must have both observed and modeled\n",
    "\n",
    "print(\"Time series dataframe format:\")\n",
    "df_ts_treatment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features dataframe format, columns: [id, feature1, feature2, ...]\n",
    "# features can be named whatever you like and you may include as many as you like\n",
    "\n",
    "print(\"Features dataframe format:\")\n",
    "df_features_treatment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up data\n",
    "\n",
    "Gridmeter uses the `Data` class as the inputs to all of the comparison group methods. Its purpose is to validate your data and to perform the necessary transformations to go into the comparison group methods. `Data` is instantiated with `Data_Settings`. Once instantiated the method `.set_data` can be called using one of `loadshape_df` and `time_series_df` as well as `features_df` depending upon your needs. If you input `time_series_df` it will compute the loadshape.\n",
    "\n",
    "Method requirements:\n",
    "- Clustering: Loadshape\n",
    "- Individual Meter Matching: Loadshape\n",
    "- Stratified Sampling: Loadshape/Features (depends upon settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_settings = gm.Data_Settings(time_period='month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make an invalid entry to see what happens\n",
    "df_ts_treatment.loc[0, 'observed'] = np.nan\n",
    "\n",
    "ts_data = gm.Data().set_data(time_series_df=df_ts_treatment)\n",
    "\n",
    "ts_data.excluded_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data classes\n",
    "# for the purposes of this tutorial, we'll set both loadshapes and features\n",
    "\n",
    "data_settings = gm.Data_Settings(time_period=None)\n",
    "\n",
    "pool_data = gm.Data(data_settings)\n",
    "pool_data.set_data(loadshape_df=df_ls_pool, features_df=df_features_pool)\n",
    "\n",
    "treatment_data = gm.Data(data_settings)\n",
    "treatment_data.set_data(loadshape_df=df_ls_treatment, features_df=df_features_treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_data.loadshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Is it fast? Not particularly, but it has advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_settings = gm.Clustering_Settings()\n",
    "df_cg, df_t_coeffs = gm.Clustering(clustering_settings).get_comparison_group(treatment_data, pool_data)\n",
    "df_cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Meter Matching\n",
    "For Euclidean distance matching, the usage patterns of each treatment meter are compared to the usage patterns of each comparison pool meter in order to find the closest matches. The subsequent group of meters that have been \"matched\" become the resulting comparison group.\n",
    "\n",
    "## Features For Matching\n",
    "\n",
    "Any usage pattern can be used for euclidean distance matching. If an 8760 hourly trace is available, it is suggested to use a 'seasonal-hour-of-week' load-shape (3 168-point load shapes, one for summer, winter, and shoulder). If only monthly data is available, it is suggested to use the 12 months of usage as the usage pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test IMM\n",
    "\n",
    "imm_settings = gm.IMM_Settings()\n",
    "df_cg, df_t_coeffs = gm.IMM(imm_settings).get_comparison_group(treatment_data, pool_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_group_distance = df_pool_distance.reindex(df_group_distance_selected.index)\n",
    "\n",
    "df_treatment_distance.mean().plot(label='treatment')\n",
    "df_group_distance.mean().plot(label='group')\n",
    "df_pool_distance.mean().plot(label='pool')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Sampling Matching\n",
    "\n",
    "There are many ways to define similarity and many methods for constructing similar groups.  The stratified sampling approach was selected in particular because it offers a good balance in terms effectiveness, ease of implementation, and simplicity. We define stratified sampling as follows:\n",
    "\n",
    "- Each meter is represented by a vector of numerical features, e.g. annual usage, summer peak usage, etc\n",
    "- A small number of features, typically between 1 and 3 inclusive, are selected: this is the number of *dimensions*.\n",
    "- The treatment group is divided up into a set of multidimensional bins according to a predefined binning configuration.\n",
    "- The proportion of treatment meters present in each bin is computed.\n",
    "- A set of meters is sampled from the comparison pool such that the sample is distributed amongst the bins in the same proportion as the treatment group.  The sample is called the comparison group.\n",
    "- The treatment and comparison groups are compared using additional meter data, e.g. load shapes.\n",
    "- (Optional) An optimal binning configuration is selected which minimizes error between treatment and control groups.\n",
    "\n",
    "\n",
    "In order to use this library, it is therefore necessary to have the following data at hand:\n",
    "- A data frame containing the treatment group, with one ID column, and a set of numerical feature columns, one row per meter;\n",
    "- A data frame containing the comparison pool, in the same format;\n",
    "- A data frame containing the treatment group data for equivalence, with one ID column, one feature name column, and one value column; e.g. for an annual monthly load shape, the feature name column might contain the month name, and there might be twelve rows per meter;\n",
    "- A data frame containing the comparison pool data for equivalence, in the same format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features for stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, you will compute a set of features from your time series meter traces, and then select a subset of those features to stratify on.  The feature computation step is up to you.  We recommend running the Caltrack model to derive heating and cooling coefficients and deriving features from these outputs.  Other techniques such as principle component analysis could be useful as well.  In general, aim for stratifying on between one and three features, and aim for orthogonal features if possible.  In the dummy data, there are three features available: `summer_usage`, `winter_usage`, and `annual_usage` which are shown in the scatter plots below.  `annual_usage` is correlated with the other two, as you would expect, so we will stratify based on `summer_usage` and `winter_usage`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df_features_treatment);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plotting the two features below we can see that the treatment group and comparison pool are differently distributed, such that a random sample from the pool would not be a good counterfactual for the treatment group -- this is why we need stratified sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.ggplot(df_features, pn.aes(x='summer_usage', y='winter_usage', color='set')) + pn.geom_point(alpha=0.5) + pn.facet_wrap(\"~set\") + pn.theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use stratified sampling, you must supply input data, a list of input columns to stratify on, and some configuration, according to the example below.   Additionally, you have the option of using the library to select an optimal configuration for you.  We'll first demonstrate the basic usage of the model, in which you supply all of the configuration information.\n",
    "\n",
    "### Number of outputs \n",
    "\n",
    "The size of the comparison group is constrained by the size of the pool and by the degree to which the treatment group overlaps the pool in terms of the stratification columns.  For example, if the treatment group and pool are disjoint, no comparison group can be constructed; if only 5% of the pool overlaps the treatment group, then the effective available pool is constructed from that 5% of overlapping meters.  Generally, if you do not specify the output size, `gridmeter` will construct the largest possible comparison group up to 5000 meters.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_col_settings = [\n",
    "    {\n",
    "        \"column_name\": \"summer_usage\", \n",
    "        \"n_bins\": 8, \n",
    "        \"min_value_allowed\": 3000, \n",
    "        \"max_value_allowed\": 6000, \n",
    "        \"fixed_width\": False\n",
    "    },\n",
    "    {\n",
    "        \"column_name\": \"winter_usage\",\n",
    "        \"n_bins\": 8, \n",
    "        \"min_value_allowed\": 3000, \n",
    "        \"max_value_allowed\": 6000, \n",
    "        \"fixed_width\": False\n",
    "    },\n",
    "]\n",
    "\n",
    "ss_settings = gm.stratified_sampling_settings(stratification_column=strat_col_settings, random_seed=1)\n",
    "ss = gm.Stratified_Sampling(ss_settings)\n",
    "\n",
    "df_clusters, df_treatment_weights = ss.get_comparison_group(treatment_data, pool_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Stratified Sampling dataframe\n",
    "ss.df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin count\n",
    "ss.diagnostics().count_bins()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing diagnostic plots \n",
    "\n",
    "Once the model has been fit, you can view several plots which will show the treatment group, comparison pool, and the final sample (i.e. the comparison group).  If the model has worked correctly, then the sample should be distributed similarly to the treatment group.  There are three plots available:\n",
    "\n",
    "1. Histograms, showing the distribution of each stratification parameter in one dimension;\n",
    "2. Scatter plots, showing an XY-plot of data points for each pair of dimensions;\n",
    "3. Quantile plots with equivalence, showing the quantile distribution of each dimension, along with t-test and ks-test p-values comparison the treatment and comparison groups.  \n",
    "\n",
    "The t- and ks-tests can be used as a measure of equivalence, however we recommend using equivalence-based optimization discussed below for better results in practice.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ss.diagnostics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.scatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.quantile_equivalence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equivalence-based optimization\n",
    "\n",
    "The above method of stratified sampling is designed to match the distributions of one or more stratification parameters.  However, often in practice the desired outcome is to have a comparison group with similar usage patterns to a treatment group as measured through a load shape or similar set of time-series features.  To ensure that the load shapes are equivalent, you can use the `StratifiedSamplingBinSelector` which selects an optimal binning arrangement which minimizes load shape error between the treatment and comparison groups. \n",
    "\n",
    "In the following example, a bin selector is used to match on monthly load shapes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_col_settings = {\n",
    "    \"equivalence_method\": \"chisquare\",\n",
    "    \"min_n_bins\": 2,\n",
    "    \"max_n_bins\": 8,\n",
    "    \"stratification_column\": [{\n",
    "            \"column_name\": \"summer_usage\", \n",
    "            \"n_bins\": None, \n",
    "            \"min_value_allowed\": 3000, \n",
    "            \"max_value_allowed\": 6000, \n",
    "            \"fixed_width\": False\n",
    "        },\n",
    "        {\n",
    "            \"column_name\": \"winter_usage\",\n",
    "            \"n_bins\": None, \n",
    "            \"min_value_allowed\": 3000, \n",
    "            \"max_value_allowed\": 6000, \n",
    "            \"fixed_width\": False\n",
    "    }],\n",
    "    \"random_seed\": 1,\n",
    "}\n",
    "\n",
    "dss_settings = gm.distance_stratified_sampling_settings(**strat_col_settings)\n",
    "dss = gm.Stratified_Sampling(dss_settings)\n",
    "\n",
    "df_clusters2, df_treatment_weights2 = dss.get_comparison_group(treatment_data, pool_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss.model_bin_selector.plot_records_based_equiv_average()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above shows the monthly load shape of the treatment group (red), the selected comparison group (black), other candidate comparison groups (blue), and the comparison pool (dots).  In this case, all of the candidates were a good match, so the selection process was probably unnecessary, however in more complex cases this method can be useful.  The final binning arrangement is available in the model object as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss.diagnostics().scatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss.df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the tutorial.  For questions, comments, or issues, please raise a Github issue here:  \n",
    "https://github.com/recurve-methods/comparison_groups/issues\n",
    "\n",
    "We thank you for your interest and participation in this project and look forward to your feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
