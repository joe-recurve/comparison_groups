{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gridmeter._utils.data_processing import Data\n",
    "from gridmeter._utils.data_processing_settings import Data_Settings\n",
    "from gridmeter._utils import const as _const\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data class in Gridmeter\n",
    "\n",
    "The data class takes input in two formats - time series and loadshapes (both stacked and unstacked versions)\n",
    "It returns an aggregated loadshape output based on the settings provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage is as follows:\n",
    "\n",
    "```python\n",
    "\n",
    "from gridmeter._utils.data_processing import Data\n",
    "from gridmeter._utils.data_processing_settings import Data_Settings\n",
    "from gridmeter._utils import const as _const\n",
    "\n",
    "# Specify a time settings object (setting the time period to be seasonal day of week, i.e. 7 days * 3 seasons = 21 data points)\n",
    "settings = Data_Settings(TIME_PERIOD=_const.TimePeriod.SEASONAL_DAY_OF_WEEK)\n",
    "\n",
    "# Use this time settings to create a data settings object\n",
    "# df here is your input dataframe (more explained later on)\n",
    "data = Data(None).set_data(time_series_df=df)\n",
    "\n",
    "# Check the output\n",
    "data.loadshape\n",
    "    \n",
    "```\n",
    "\n",
    "Lets look at a few examples into the different types of input and possible outputs/return values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series loadshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a testing dataframe having an id, datetime of 15 min intervals, observed and modeled values\n",
    "num_intervals = 4 * 24 * 365  # 4 intervals/hour * 24 hours/day * 365 days\n",
    "\n",
    "# Create a DataFrame with 'id', 'datetime', 'observed', and 'modeled' columns\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": np.repeat(\n",
    "            [\"id1\", \"id2\", \"id3\"], num_intervals\n",
    "        ),  # only 3 ids for easier comparison\n",
    "        \"datetime\": pd.date_range(\n",
    "            start=\"2023-01-01\", periods=num_intervals, freq=\"15T\"\n",
    "        ).tolist()\n",
    "        * 3,\n",
    "        \"observed\": np.random.rand(num_intervals * 3),  # randomized\n",
    "        \"modeled\": np.random.rand(num_intervals * 3),  # randomized\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert 'datetime' column to datetime type\n",
    "# df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can have Settings as None, which will use default settings\n",
    "\n",
    "\n",
    "data1 = Data(None).set_data(time_series_df=df)\n",
    "data1.get_loadshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a different Time Period setting\n",
    "\n",
    "settings = Data_Settings(TIME_PERIOD=_const.TimePeriod.SEASONAL_DAY_OF_WEEK)\n",
    "\n",
    "\n",
    "data = Data(settings).set_data(time_series_df=df)\n",
    "data.get_loadshape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also join two loadshapes if they have the same time_period classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_df = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": np.repeat(\n",
    "            [\"id4\", \"id5\", \"id6\"], num_intervals\n",
    "        ),  # only 3 ids for easier comparison\n",
    "        \"datetime\": pd.date_range(\n",
    "            start=\"2023-01-01\", periods=num_intervals, freq=\"15T\"\n",
    "        ).tolist()\n",
    "        * 3,\n",
    "        \"observed\": np.random.rand(num_intervals * 3),  # randomized\n",
    "        \"modeled\": np.random.rand(num_intervals * 3),  # randomized\n",
    "    }\n",
    ")\n",
    "\n",
    "extended_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Data_Settings(TIME_PERIOD=_const.TimePeriod.SEASONAL_DAY_OF_WEEK)\n",
    "data_extended = Data(settings).set_data(time_series_df=extended_df)\n",
    "data_extended.get_loadshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extended.extend(data)\n",
    "data_extended.get_loadshape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTERPOLATION\n",
    "\n",
    "We interpolate values that are missing in the dataframe linearly, given that the amount of missing data is lower than the interpolation threshold (default is 20% of the total data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the missing data to lower than 80% threshold. It should return a loadshape which has been interpolated\n",
    "## Create a boolean mask for Wednesdays\n",
    "day_mask = df['datetime'].dt.dayofweek.isin([2])\n",
    "\n",
    "# # Set 'observed' and 'modeled' values to NaN for all Mondays and Wednesdays\n",
    "# df.loc[day_mask, ['observed', 'modeled']] = np.nan\n",
    "\n",
    "# # Remove all rows with NaN values\n",
    "df = df.loc[~day_mask]\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Data_Settings(TIME_PERIOD=_const.TimePeriod.DAY_OF_WEEK)\n",
    "data = Data(settings).set_data(time_series_df=df)\n",
    "data.get_loadshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now , Create a boolean mask for Mondays and Wednesdays , will give ValueError at 80% threshold\n",
    "day_mask = df['datetime'].dt.dayofweek.isin([0,2])\n",
    "\n",
    "# # Set 'observed' and 'modeled' values to NaN for all Mondays and Wednesdays\n",
    "# df.loc[day_mask, ['observed', 'modeled']] = np.nan\n",
    "\n",
    "# # Remove all rows with NaN values\n",
    "df = df.loc[~day_mask]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the above missing data to try to create a loadshape. Since we have 2 days missing out of 7 for every id, it returns None\n",
    "\n",
    "settings = Data_Settings(TIME_PERIOD=_const.TimePeriod.DAY_OF_WEEK)\n",
    "data = Data(settings).set_data(time_series_df=df)\n",
    "data.get_loadshape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unstacked loadshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming ids is a list of unique ids\n",
    "ids = [\"id1\", \"id2\", \"id3\"]\n",
    "\n",
    "# Create a range of values\n",
    "values = range(1, _const.time_period_row_counts[\"day_of_week\"] + 1)\n",
    "row_cnt_per_id = 1\n",
    "\n",
    "# Repeat each id len(values) times and tile values len(ids) times\n",
    "df_new = pd.DataFrame({\n",
    "    'id': np.repeat(ids, row_cnt_per_id),\n",
    "    **{str(i): np.random.randint(1, 100, len(ids) * row_cnt_per_id) for i in range(1, len(values) + 1)}\n",
    "})\n",
    "\n",
    "# Create a boolean mask with True values representing 10% of the total number of elements\n",
    "mask = np.random.choice([True, False], size=df_new.drop('id', axis=1).shape, p=[0.2, 0.8])\n",
    "\n",
    "# Use the mask to set 10% of the values in df_new to NaN, excluding 'id' column\n",
    "df_new.loc[:, df_new.columns != 'id'] = df_new.drop('id', axis=1).where(~mask, np.nan)\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AGG_TYPE, LOADSHAPE_TYPE and TIME_PERIOD must be set to None if we're using loadshapes.\n",
    "They're only required for time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Data_Settings(AGG_TYPE = None, LOADSHAPE_TYPE = None, TIME_PERIOD = None, INTERPOLATE_MISSING = True)\n",
    "unstack_df = df_new.copy()\n",
    "data_new = Data(settings).set_data(loadshape_df=unstack_df)\n",
    "data_new.get_loadshape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Loadshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [\"id1\", \"id2\", \"id3\"]\n",
    "\n",
    "# Given count number of time values\n",
    "count = 7\n",
    "\n",
    "# Create a DataFrame\n",
    "loadshape_df = pd.DataFrame({\n",
    "    'id': np.repeat(ids, count),\n",
    "    'time': np.tile(range(1, count + 1), len(ids)),\n",
    "    'loadshape': np.random.rand(len(ids) * count)\n",
    "})\n",
    "\n",
    "loadshape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Data_Settings(AGG_TYPE = None, LOADSHAPE_TYPE = None, TIME_PERIOD = None, INTERPOLATE_MISSING = True)\n",
    "data_loadshape = Data(settings).set_data(loadshape_df=loadshape_df)\n",
    "data_loadshape.get_loadshape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features input\n",
    "\n",
    "id cooling_load heating_load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
